{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try running a single ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"/scratch/users/nphill22/projects/corsello_lab/20240313_prism_final_reruns/new_baseline/processed_data/x-all.pkl\"\n",
    "response_path = \"/scratch/users/nphill22/projects/corsello_lab/20240313_prism_final_reruns/data/features/responses/amg-232_2.5.csv\"\n",
    "output_dir = \"nn_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading feature data...\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "logger.info(\"Loading feature data...\")\n",
    "with open(feature_path, \"rb\") as f:\n",
    "    feature_df = pickle.load(f)\n",
    "feature_df.set_index(\"ccle_name\", inplace=True)\n",
    "feature_df.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading response data...\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Loading response data...\")\n",
    "response_df = pd.read_csv(response_path)\n",
    "\n",
    "# only keep cell lines we have features for\n",
    "available_ccle_names = set(feature_df.index)\n",
    "response_df = response_df[response_df[\"ccle_name\"].isin(available_ccle_names)]\n",
    "\n",
    "# drop culture column\n",
    "response_df = response_df.drop(columns=[\"culture\"])\n",
    "# drop duplicates by ccle_name, keep first\n",
    "response_df = response_df.drop_duplicates(subset=[\"ccle_name\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from refract.trainers import *\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# train test val split on response_df ccle_names\n",
    "train_ccle_names, test_ccle_names = train_test_split(response_df[\"ccle_name\"], test_size=0.2, random_state=42)\n",
    "train_ccle_names, val_ccle_names = train_test_split(train_ccle_names, test_size=0.2, random_state=42)\n",
    "\n",
    "# get response_train, response_val, response_test dfs in order \n",
    "response_train_df = response_df.loc[response_df.ccle_name.isin(train_ccle_names)]\n",
    "response_val_df = response_df.loc[response_df.ccle_name.isin(val_ccle_names)]\n",
    "response_test_df = response_df.loc[response_df.ccle_name.isin(test_ccle_names)]\n",
    "\n",
    "# drop all columns with zero stddev\n",
    "feature_df = feature_df.loc[:, feature_df.std() != 0]\n",
    "\n",
    "X_train_df = feature_df.loc[response_train_df.ccle_name.values, :]\n",
    "X_val_df = feature_df.loc[response_val_df.ccle_name.values, :]\n",
    "X_test_df = feature_df.loc[response_test_df.ccle_name.values, :]\n",
    "\n",
    "top_features = get_n_correlated_features(\n",
    "    response_train_df['LFC.cb'].values,\n",
    "    X_train_df.values,\n",
    "    X_train_df.columns,\n",
    "    n=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the responses for all compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_files = glob.glob(\"/scratch/users/nphill22/projects/corsello_lab/20240313_prism_final_reruns/data/features/responses/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6513/6513 [00:22<00:00, 292.85it/s]\n"
     ]
    }
   ],
   "source": [
    "all_responses = []\n",
    "for response_path in tqdm.tqdm(response_files):\n",
    "    response_df = pd.read_csv(response_path)\n",
    "    df = response_df.loc[:, [\"ccle_name\", \"pert_name\", \"pert_idose\", \"LFC.cb\"]]\n",
    "    # concatenate pert_name and pert_idose\n",
    "    df[\"pert_name\"] = df[\"pert_name\"] + \"_\" + df[\"pert_idose\"].astype(str)\n",
    "    df = df.drop(columns=[\"pert_idose\"])\n",
    "    all_responses.append(df)\n",
    "response_df = pd.concat(all_responses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccle_name</th>\n",
       "      <th>pert_name</th>\n",
       "      <th>LFC.cb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIHOVCAR3_OVARY</td>\n",
       "      <td>micafungin_2.5</td>\n",
       "      <td>-0.079331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HL60_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE</td>\n",
       "      <td>micafungin_2.5</td>\n",
       "      <td>0.753126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEL_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE</td>\n",
       "      <td>micafungin_2.5</td>\n",
       "      <td>-0.038481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEL9217_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE</td>\n",
       "      <td>micafungin_2.5</td>\n",
       "      <td>-0.125686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MONOMAC6_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE</td>\n",
       "      <td>micafungin_2.5</td>\n",
       "      <td>1.384392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ccle_name       pert_name    LFC.cb\n",
       "0                              NIHOVCAR3_OVARY  micafungin_2.5 -0.079331\n",
       "1      HL60_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE  micafungin_2.5  0.753126\n",
       "2       HEL_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE  micafungin_2.5 -0.038481\n",
       "3   HEL9217_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE  micafungin_2.5 -0.125686\n",
       "4  MONOMAC6_HAEMATOPOIETIC_AND_LYMPHOID_TISSUE  micafungin_2.5  1.384392"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GE_TSPAN6</th>\n",
       "      <th>GE_TNMD</th>\n",
       "      <th>GE_DPM1</th>\n",
       "      <th>GE_SCYL3</th>\n",
       "      <th>GE_C1orf112</th>\n",
       "      <th>GE_FGR</th>\n",
       "      <th>GE_CFH</th>\n",
       "      <th>GE_FUCA2</th>\n",
       "      <th>GE_GCLC</th>\n",
       "      <th>GE_NFYA</th>\n",
       "      <th>...</th>\n",
       "      <th>MET_C56:8 TAG</th>\n",
       "      <th>MET_C56:7 TAG</th>\n",
       "      <th>MET_C56:6 TAG</th>\n",
       "      <th>MET_C56:5 TAG</th>\n",
       "      <th>MET_C56:4 TAG</th>\n",
       "      <th>MET_C56:3 TAG</th>\n",
       "      <th>MET_C56:2 TAG</th>\n",
       "      <th>MET_C58:8 TAG</th>\n",
       "      <th>MET_C58:7 TAG</th>\n",
       "      <th>MET_C58:6 TAG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccle_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127399_SOFT_TISSUE</th>\n",
       "      <td>3.243364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.863567</td>\n",
       "      <td>2.063503</td>\n",
       "      <td>3.916477</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>5.426600</td>\n",
       "      <td>3.820690</td>\n",
       "      <td>2.976364</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321N1_CENTRAL_NERVOUS_SYSTEM</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143B_BONE</th>\n",
       "      <td>4.719731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.360540</td>\n",
       "      <td>1.778209</td>\n",
       "      <td>3.786596</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.713696</td>\n",
       "      <td>5.393348</td>\n",
       "      <td>4.638074</td>\n",
       "      <td>3.046142</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170MGBA_CENTRAL_NERVOUS_SYSTEM</th>\n",
       "      <td>4.155425</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>6.681590</td>\n",
       "      <td>2.430285</td>\n",
       "      <td>2.799087</td>\n",
       "      <td>0.815575</td>\n",
       "      <td>3.559492</td>\n",
       "      <td>7.252855</td>\n",
       "      <td>4.300856</td>\n",
       "      <td>3.682573</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184A1_BREAST</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                GE_TSPAN6   GE_TNMD   GE_DPM1  GE_SCYL3  \\\n",
       "ccle_name                                                                 \n",
       "127399_SOFT_TISSUE               3.243364  0.000000  6.863567  2.063503   \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM   -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "143B_BONE                        4.719731  0.000000  7.360540  1.778209   \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM   4.155425  0.124328  6.681590  2.430285   \n",
       "184A1_BREAST                    -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "\n",
       "                                GE_C1orf112    GE_FGR    GE_CFH  GE_FUCA2  \\\n",
       "ccle_name                                                                   \n",
       "127399_SOFT_TISSUE                 3.916477  0.070389  0.056584  5.426600   \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM     -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "143B_BONE                          3.786596  0.014355  0.713696  5.393348   \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM     2.799087  0.815575  3.559492  7.252855   \n",
       "184A1_BREAST                      -1.000000 -1.000000 -1.000000 -1.000000   \n",
       "\n",
       "                                 GE_GCLC   GE_NFYA  ...  MET_C56:8 TAG  \\\n",
       "ccle_name                                           ...                  \n",
       "127399_SOFT_TISSUE              3.820690  2.976364  ...           -1.0   \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM  -1.000000 -1.000000  ...           -1.0   \n",
       "143B_BONE                       4.638074  3.046142  ...           -1.0   \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM  4.300856  3.682573  ...           -1.0   \n",
       "184A1_BREAST                   -1.000000 -1.000000  ...           -1.0   \n",
       "\n",
       "                                MET_C56:7 TAG  MET_C56:6 TAG  MET_C56:5 TAG  \\\n",
       "ccle_name                                                                     \n",
       "127399_SOFT_TISSUE                       -1.0           -1.0           -1.0   \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM            -1.0           -1.0           -1.0   \n",
       "143B_BONE                                -1.0           -1.0           -1.0   \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM           -1.0           -1.0           -1.0   \n",
       "184A1_BREAST                             -1.0           -1.0           -1.0   \n",
       "\n",
       "                                MET_C56:4 TAG  MET_C56:3 TAG  MET_C56:2 TAG  \\\n",
       "ccle_name                                                                     \n",
       "127399_SOFT_TISSUE                       -1.0           -1.0           -1.0   \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM            -1.0           -1.0           -1.0   \n",
       "143B_BONE                                -1.0           -1.0           -1.0   \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM           -1.0           -1.0           -1.0   \n",
       "184A1_BREAST                             -1.0           -1.0           -1.0   \n",
       "\n",
       "                                MET_C58:8 TAG  MET_C58:7 TAG  MET_C58:6 TAG  \n",
       "ccle_name                                                                    \n",
       "127399_SOFT_TISSUE                       -1.0           -1.0           -1.0  \n",
       "1321N1_CENTRAL_NERVOUS_SYSTEM            -1.0           -1.0           -1.0  \n",
       "143B_BONE                                -1.0           -1.0           -1.0  \n",
       "170MGBA_CENTRAL_NERVOUS_SYSTEM           -1.0           -1.0           -1.0  \n",
       "184A1_BREAST                             -1.0           -1.0           -1.0  \n",
       "\n",
       "[5 rows x 110135 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for model componenets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, make a dataset to return the data in expected format\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class PrismDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, feature_df, response_df, drug_name_encoder, \\\n",
    "            cell_line_col=\"ccle_name\", response_col=\"LFC.cb\", drug_col=\"pert_name\"):\n",
    "        self.feature_df = feature_df\n",
    "        self.response_df = response_df\n",
    "        self.cell_line_col = cell_line_col\n",
    "        self.response_col = response_col\n",
    "        self.drug_col = drug_col\n",
    "\n",
    "        self.drug_names = self.response_df[self.drug_col].values\n",
    "        # encode drug names as integers\n",
    "        self.drug_name_encoder = drug_name_encoder\n",
    "        self.drug_names = self.drug_name_encoder.transform(self.drug_names)\n",
    "        self.cell_lines = self.response_df[self.cell_line_col].values\n",
    "        self.responses = self.response_df[self.response_col].values\n",
    "        self.num_embeddings = len(self.drug_name_encoder.classes_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.responses)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        response = self.responses[idx]\n",
    "        drug = self.drug_names[idx]\n",
    "        cell_line = self.cell_lines[idx]\n",
    "        features = self.feature_df.loc[cell_line, :].values\n",
    "\n",
    "        # return all as tensors\n",
    "        response = torch.tensor(response, dtype=torch.float32)\n",
    "        drug = torch.tensor(drug, dtype=torch.long)\n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "        return features, drug, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_model(input_dim, num_embeddings, embedding_dim, dropout_rate=0.5):\n",
    "    # Define a simple feedforward neural network structure with an embedding layer, dropout, and batch normalization\n",
    "    class FeedforwardNeuralNetwork(nn.Module):\n",
    "        def __init__(self, input_dim, num_embeddings, embedding_dim, dropout_rate):\n",
    "            super(FeedforwardNeuralNetwork, self).__init__()\n",
    "            # Define an embedding layer for perturbation names\n",
    "            self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "            # Define three hidden layers and output layer\n",
    "            self.fc1 = nn.Linear(input_dim + embedding_dim, 128)  # First hidden layer, adjusted for embedding\n",
    "            self.fc2 = nn.Linear(128, 64)                        # Second hidden layer\n",
    "            self.fc3 = nn.Linear(64, 32)                         # Third hidden layer\n",
    "            self.fc4 = nn.Linear(32, 1)                          # Output layer\n",
    "            # Dropout layers\n",
    "            self.dropout1 = nn.Dropout(dropout_rate)\n",
    "            self.dropout2 = nn.Dropout(dropout_rate)\n",
    "            self.dropout3 = nn.Dropout(dropout_rate)\n",
    "            # Batch normalization layers\n",
    "            self.bn1 = nn.BatchNorm1d(128)\n",
    "            self.bn2 = nn.BatchNorm1d(64)\n",
    "            self.bn3 = nn.BatchNorm1d(32)\n",
    "\n",
    "        def forward(self, x, pert_name):\n",
    "            x = x.float()\n",
    "            # Embedding for the perturbation name\n",
    "            pert_embedding = self.embedding(pert_name).float()\n",
    "            # Concatenate the embedding with the input features\n",
    "            x = torch.cat([x, pert_embedding], dim=1)\n",
    "            # Activation functions, batch normalization, and dropout for the hidden layers\n",
    "            x = F.relu(self.bn1(self.fc1(x)))\n",
    "            x = self.dropout1(x)\n",
    "            x = F.relu(self.bn2(self.fc2(x)))\n",
    "            x = self.dropout2(x)\n",
    "            x = F.relu(self.bn3(self.fc3(x)))\n",
    "            x = self.dropout3(x)\n",
    "            x = self.fc4(x)  # No activation for output layer, assuming regression task\n",
    "            return x\n",
    "\n",
    "    # Create the neural network model\n",
    "    model = FeedforwardNeuralNetwork(input_dim, num_embeddings, embedding_dim, dropout_rate)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename=\"model_checkpoint_{}.pth\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename.format(epoch))\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, num_epochs, patience):\n",
    "    # Assuming the loss function and optimizer are predefined globally or are parameters\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        train_loss = 0\n",
    "        for inputs, cell_line, targets in tqdm.tqdm(train_dataloader):\n",
    "            inputs, cell_line, targets = inputs.to(device), cell_line.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs, cell_line).squeeze().float()\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "        # Log training loss\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, cell_line, targets in val_dataloader:\n",
    "                inputs, cell_line, targets = inputs.to(device), cell_line.to(device), targets.to(device)\n",
    "                outputs = model(inputs, cell_line).squeeze().float()\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        val_loss /= len(val_dataloader.dataset)\n",
    "\n",
    "        # Log validation loss\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "        save_checkpoint(model, optimizer, epoch, loss)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "    # Load the best model back\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Example call to the training function:\n",
    "# train_model(model, train_loader, val_loader, num_epochs=50, patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep responses we have features for\n",
    "response_df = response_df[response_df[\"ccle_name\"].isin(available_ccle_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the responses by train, val, test on ccle_name\n",
    "response_train = response_df[response_df[\"ccle_name\"].isin(train_ccle_names)]\n",
    "response_val = response_df[response_df[\"ccle_name\"].isin(val_ccle_names)]\n",
    "response_test = response_df[response_df[\"ccle_name\"].isin(test_ccle_names)]\n",
    "\n",
    "# filter X_train, X_val, X_test to only top features\n",
    "#X_train = X_train_df.loc[:, top_features]\n",
    "#X_val = X_val_df.loc[:, top_features]\n",
    "#X_test = X_test_df.loc[:, top_features]\n",
    "\n",
    "X_train = X_train_df.copy()\n",
    "X_val = X_val_df.copy()\n",
    "X_test = X_test_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scale the features, return dataframes\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_encoder = LabelEncoder()\n",
    "drugs = response_df.pert_name.unique()\n",
    "drug_encoder = drug_encoder.fit(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('drug_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(drug_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "train_dataset = PrismDataset(X_train, response_train, drug_encoder)\n",
    "val_dataset = PrismDataset(X_val, response_val, drug_encoder)\n",
    "test_dataset = PrismDataset(X_test, response_test, drug_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for training and test\n",
    "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=24)\n",
    "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=24)\n",
    "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1024, shuffle=False, num_workers=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model \n",
    "model = get_model(input_dim=X_train.shape[1], num_embeddings=train_dataset.num_embeddings, embedding_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedforwardNeuralNetwork(\n",
       "  (embedding): Embedding(6513, 10)\n",
       "  (fc1): Linear(in_features=110145, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:16<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train Loss: 1.1800, Val Loss: 1.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:37<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/200], Train Loss: 0.9632, Val Loss: 0.5713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:28<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/200], Train Loss: 0.6084, Val Loss: 0.4897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:30<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/200], Train Loss: 0.5403, Val Loss: 0.4697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [09:17<00:00,  4.08it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/200], Train Loss: 0.5112, Val Loss: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:31<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/200], Train Loss: 0.4905, Val Loss: 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:27<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/200], Train Loss: 0.4795, Val Loss: 0.5307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:37<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/200], Train Loss: 0.4678, Val Loss: 0.5303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:32<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/200], Train Loss: 0.4603, Val Loss: 0.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:41<00:00,  4.37it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Train Loss: 0.4555, Val Loss: 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:27<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/200], Train Loss: 0.4492, Val Loss: 0.4372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:31<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/200], Train Loss: 0.4450, Val Loss: 0.4842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:27<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/200], Train Loss: 0.4411, Val Loss: 0.4402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:23<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/200], Train Loss: 0.4396, Val Loss: 0.4161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:25<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/200], Train Loss: 0.4370, Val Loss: 0.4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2276/2276 [08:30<00:00,  4.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dl, val_dl, num_epochs=200, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint model to disk\n",
    "#checkpoint = {\n",
    "#    \"model_state_dict\": model.state_dict()\n",
    "#}\n",
    "#torch.save(checkpoint, \"initial_model_full_train.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict = torch.load('best_model.pth', map_location=torch.device('cpu'))\n",
    "#model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 393489/753472 [22:44<20:48, 288.36it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m f, d, l \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(test_dataset):\n\u001b[1;32m      4\u001b[0m     \u001b[39m# drug \u001b[39;00m\n\u001b[1;32m      5\u001b[0m     drug_name \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mdrug_name_encoder\u001b[39m.\u001b[39minverse_transform([d\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()])\n\u001b[0;32m----> 6\u001b[0m     p \u001b[39m=\u001b[39m model(f\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m), d\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m     out\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mdrug_name\u001b[39m\u001b[39m\"\u001b[39m: drug_name, \u001b[39m\"\u001b[39m\u001b[39mtrue\u001b[39m\u001b[39m\"\u001b[39m: l\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(), \u001b[39m\"\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m\"\u001b[39m: p\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()})\n",
      "File \u001b[0;32m/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m, in \u001b[0;36mget_model.<locals>.FeedforwardNeuralNetwork.forward\u001b[0;34m(self, x, pert_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, pert_embedding], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39m# Activation functions for the hidden layers\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))  \u001b[39m# Activation function for first layer\u001b[39;00m\n\u001b[1;32m     26\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))  \u001b[39m# Activation function for second layer\u001b[39;00m\n\u001b[1;32m     27\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))  \u001b[39m# Activation function for third layer\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/groups/corsello/nphill22/tools/miniconda3/envs/lab/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = []\n",
    "\n",
    "for f, d, l in tqdm.tqdm(test_dataset):\n",
    "    # drug \n",
    "    drug_name = train_dataset.drug_name_encoder.inverse_transform([d.detach().numpy()])\n",
    "    p = model(f.unsqueeze(0), d.unsqueeze(0))\n",
    "    out.append({\"drug_name\": drug_name, \"true\": l.detach().numpy(), \"pred\": p.detach().numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df.drug_name = [i[0] for i in train_results_df.drug_name.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df.pred = [i[0][0] for i in train_results_df.pred.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose compound amg-232\n",
    "tmp = train_results_df.loc[train_results_df.drug_name == \"amg-232_2.5\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff72e7cc1c0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(tmp.true, tmp.pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_df.to_csv(\"init_train_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_train.to_csv(\"response_train.csv\")\n",
    "response_test.to_csv(\"response_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
